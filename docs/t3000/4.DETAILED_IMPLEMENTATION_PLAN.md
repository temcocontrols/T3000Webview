# T3000 Trendlog Implementation - Detailed Step-by-Step Plan

**Date:** August 7, 2025
**Status:** Pre-Implementation Phase
**Estimated Timeline:** 3-4 weeks

---

## 🎯 Implementation Overview

This plan implements historical data storage for T3000 WebView while preserving all existing functionality. The solution uses a separate SQLite database for trendlog data with automatic background collection.

### Key Features to Implement:
- ✅ Separate trendlog database (trendlog_database.db)
- ✅ Background data collection service
- ✅ Real-time WebSocket updates for trending
- ✅ REST API for historical data queries
- ✅ Vue.js frontend integration
- ✅ Multiple timebase support (1min - 4day intervals)

---

## 📋 Phase 1: Clean Slate Preparation (Days 1-2)

### Step 1.1: Execute Rollback
**Time:** 1 hour
**Status:** ❌ Not Started

Remove all previous data_management implementation:

```bash
# Execute in api/ directory
cd api

# 1. Remove migration file
rm migration/src/m20250122_000000_data_management_schema.rs

# 2. Remove entity directory
rm -rf src/entity/data_management/

# 3. Edit lib.rs - remove data_management module
# Remove line: pub mod data_management;

# 4. Edit migration lib.rs
# Remove line: mod m20250122_000000_data_management_schema;
# Remove from migrations vector

# 5. Verify compilation
cargo check
```

**Deliverables:**
- [ ] All data_management files removed
- [ ] Compilation successful
- [ ] Migration test passes

### Step 1.2: Verify Current System State
**Time:** 30 minutes

```bash
# Test current functionality
cargo run  # Should start on ports 9103/9104
# Test WebView2 communication
# Verify modbus_register functionality intact
```

**Acceptance Criteria:**
- [ ] Rust API server starts successfully
- [ ] WebView2 communication works
- [ ] No compilation errors
- [ ] Existing features unchanged

---

## 🗄️ Phase 2: Trendlog Database Setup (Days 3-5)

### Step 2.1: Create Trendlog Database Schema
**Time:** 4 hours
**Files:** New migration file for trendlog database

```bash
# Create new migration for trendlog database
cd api/migration
cargo run -- generate create_trendlog_schema
```

**Migration Content:**
```rust
// m20250807_000000_create_trendlog_schema.rs
pub struct Migration;

#[async_trait::async_trait]
impl MigrationTrait for Migration {
    async fn up(&self, manager: &SchemaManager) -> Result<(), DbErr> {
        // Create separate trendlog database connection
        // Tables: devices, trend_points, trend_data, timebase_config
    }
}
```

**Database Tables:**
1. **devices** - Device registry for trending
2. **trend_points** - Point definitions with collection settings
3. **trend_data** - Time-series historical data
4. **timebase_config** - T3000 standard intervals (1min-4day)

### Step 2.2: Implement Dual Database Connection
**Time:** 3 hours
**Files:** `api/src/db_connection.rs`, `api/src/app_state.rs`

```rust
// Add to app_state.rs
pub struct AppState {
    pub conn: Arc<Mutex<DatabaseConnection>>,           // Existing webview DB
    pub trendlog_conn: Arc<Mutex<DatabaseConnection>>,  // New trendlog DB
}
```

**Connection Logic:**
- webview_database.db: Existing modbus/user data
- trendlog_database.db: Historical trending data
- Independent operation for reliability

### Step 2.3: Create Trendlog Entities
**Time:** 2 hours
**Directory:** `api/src/entity/trendlog/`

**Files to Create:**
```
api/src/entity/trendlog/
├── mod.rs
├── devices.rs
├── trend_points.rs
├── trend_data.rs
└── timebase_config.rs
```

**Entity Definitions:**
- Device management for trending
- Point configuration with intervals
- Time-series data storage
- Timebase interval definitions

---

## ⚙️ Phase 3: Background Collection Service (Days 6-10)

### Step 3.1: T3000 Integration Layer
**Time:** 6 hours
**Files:** `api/src/t3000_integration.rs`

**C++ Function Bindings:**
```rust
extern "C" {
    fn t3000_read_device_point(device_id: u32, point_type: u32, point_number: u32) -> f64;
    fn t3000_get_device_status(device_id: u32) -> u32;
    fn t3000_get_device_list() -> *const DeviceInfo;
}
```

**Integration Points:**
- Read device data from T3000 C++ layer
- Device discovery and status monitoring
- Point value retrieval with error handling
- Communication protocol abstraction

### Step 3.2: Collection Service Implementation
**Time:** 8 hours
**Files:** `api/src/collection_service.rs`

**Service Architecture:**
```rust
pub struct CollectionService {
    trendlog_conn: Arc<Mutex<DatabaseConnection>>,
    collection_tasks: HashMap<u32, JoinHandle<()>>,
    shutdown_signal: Arc<AtomicBool>,
}

impl CollectionService {
    pub async fn start_collection(&mut self, device_id: u32) -> Result<(), Error>
    pub async fn stop_collection(&mut self, device_id: u32) -> Result<(), Error>
    pub async fn collect_device_data(&self, device_id: u32) -> Result<Vec<PointData>, Error>
}
```

**Collection Loop:**
```
Every Interval (configurable per point):
1. Check device status (online/offline)
2. Read all enabled points for device
3. Validate data quality
4. Store to trend_data table
5. Broadcast real-time updates via WebSocket
6. Handle errors and retry logic
```

### Step 3.3: Timebase Configuration
**Time:** 2 hours
**Files:** `api/src/timebase.rs`

**T3000 Standard Intervals:**
```rust
pub enum TimebaseInterval {
    OneMinute = 60,
    FiveMinutes = 300,
    FifteenMinutes = 900,
    ThirtyMinutes = 1800,
    OneHour = 3600,
    TwoHours = 7200,
    FourHours = 14400,
    OneDay = 86400,
    FourDays = 345600,
}
```

**Configuration Features:**
- Per-point interval configuration
- Automatic data retention policies
- Storage optimization for different intervals
- Historical data aggregation

---

## 🔌 Phase 4: API Development (Days 11-15)

### Step 4.1: Trendlog REST API Endpoints
**Time:** 6 hours
**Files:** `api/src/trendlog/routes.rs`

**API Endpoints:**
```rust
// Device Management
GET    /api/trendlog/devices              // List devices with trending enabled
POST   /api/trendlog/devices              // Add device to trending
PUT    /api/trendlog/devices/{id}         // Update device settings
DELETE /api/trendlog/devices/{id}         // Remove device from trending

// Point Configuration
GET    /api/trendlog/points/{device_id}   // Get device trend points
POST   /api/trendlog/points               // Configure point for trending
PUT    /api/trendlog/points/{id}          // Update point settings
DELETE /api/trendlog/points/{id}          // Disable point trending

// Historical Data Queries
GET    /api/trendlog/data/{point_id}      // Get historical data
POST   /api/trendlog/data/query           // Advanced data queries
GET    /api/trendlog/data/export          // Export data (CSV/Excel)

// Real-time Status
GET    /api/trendlog/status               // Collection service status
POST   /api/trendlog/control              // Start/stop collection
```

### Step 4.2: WebSocket Real-time Updates
**Time:** 4 hours
**Files:** `api/src/websocket_handler.rs`

**WebSocket Message Types:**
```rust
#[derive(Serialize, Deserialize)]
pub enum TrendlogMessage {
    TrendUpdate {
        point_id: u32,
        timestamp: i64,
        value: f64,
        quality: u8
    },
    DeviceStatus {
        device_id: u32,
        online: bool,
        last_seen: i64
    },
    CollectionStatus {
        active_points: u32,
        collection_rate: f64,
        errors: Vec<String>
    },
}
```

**Real-time Broadcasting:**
- Live data updates to all connected clients
- Device status changes
- Collection service status updates
- Error notifications

### Step 4.3: Data Query Optimization
**Time:** 4 hours
**Files:** `api/src/trendlog/queries.rs`

**Query Features:**
```rust
pub struct TrendDataQuery {
    pub point_ids: Vec<u32>,
    pub start_time: i64,
    pub end_time: i64,
    pub aggregation: Option<AggregationType>,
    pub max_points: Option<u32>,
}

pub enum AggregationType {
    Average,
    Minimum,
    Maximum,
    Sample,
}
```

**Performance Optimizations:**
- Indexed queries by timestamp
- Data aggregation for large time ranges
- Pagination for large datasets
- Caching for frequently accessed data

---

## 🎨 Phase 5: Frontend Integration (Days 16-20)

### Step 5.1: Update TrendLogChart.vue Component
**Time:** 8 hours
**Files:** `src/components/TrendLogChart.vue`

**Component Features:**
```vue
<template>
  <div class="trend-chart-container">
    <!-- Device Selection -->
    <device-selector v-model="selectedDevices" />

    <!-- Point Selection -->
    <point-selector :devices="selectedDevices" v-model="selectedPoints" />

    <!-- Time Range Controls -->
    <time-range-picker v-model="timeRange" />

    <!-- Chart Display -->
    <chart-js
      :data="chartData"
      :options="chartOptions"
      @zoom="handleZoom"
      @pan="handlePan"
    />

    <!-- Real-time Controls -->
    <realtime-controls
      v-model="realtimeEnabled"
      :update-interval="updateInterval"
    />
  </div>
</template>
```

**Key Features:**
- Multiple device/point selection
- Interactive time range selection
- Real-time data streaming toggle
- Chart zoom/pan functionality
- Data export capabilities

### Step 5.2: WebSocket Integration
**Time:** 3 hours
**Files:** `src/composables/useTrendlog.js`

**Vue Composable:**
```javascript
export function useTrendlog() {
  const websocket = ref(null);
  const chartData = ref([]);
  const isConnected = ref(false);

  const connectWebSocket = () => {
    websocket.value = new WebSocket('ws://localhost:9104');
    websocket.value.onmessage = handleMessage;
  };

  const handleMessage = (event) => {
    const data = JSON.parse(event.data);
    if (data.type === 'TrendUpdate') {
      updateChartData(data);
    }
  };

  return {
    chartData,
    isConnected,
    connectWebSocket,
    subscribeToPoint,
    unsubscribeFromPoint,
  };
}
```

### Step 5.3: Historical Data API Integration
**Time:** 4 hours
**Files:** `src/api/trendlog.js`

**API Client:**
```javascript
export class TrendlogAPI {
  async getDevices() {
    return await fetch('/api/trendlog/devices').then(r => r.json());
  }

  async getPoints(deviceId) {
    return await fetch(`/api/trendlog/points/${deviceId}`).then(r => r.json());
  }

  async getHistoricalData(pointId, startTime, endTime) {
    const params = new URLSearchParams({
      point_id: pointId,
      start_time: startTime,
      end_time: endTime,
    });
    return await fetch(`/api/trendlog/data?${params}`).then(r => r.json());
  }

  async exportData(query) {
    return await fetch('/api/trendlog/data/export', {
      method: 'POST',
      body: JSON.stringify(query),
    });
  }
}
```

---

## 🧪 Phase 6: Testing & Integration (Days 21-28)

### Step 6.1: Unit Testing
**Time:** 8 hours
**Files:** `api/tests/`

**Test Coverage:**
```rust
// Database tests
#[tokio::test]
async fn test_trendlog_database_operations() {
    // Test CRUD operations for all entities
    // Test data integrity constraints
    // Test migration rollback/forward
}

// Collection service tests
#[tokio::test]
async fn test_background_collection() {
    // Test device data collection
    // Test error handling and retry logic
    // Test collection scheduling
}

// API endpoint tests
#[tokio::test]
async fn test_trendlog_api_endpoints() {
    // Test all REST endpoints
    // Test data validation
    // Test error responses
}
```

### Step 6.2: Integration Testing
**Time:** 6 hours

**Test Scenarios:**
1. **Full System Test:**
   - Start T3000 with multiple devices
   - Enable trending on various points
   - Verify data collection and storage
   - Test real-time WebSocket updates

2. **Performance Testing:**
   - 40 devices with 256 points each
   - Various collection intervals
   - Concurrent user access
   - Large historical data queries

3. **Error Handling:**
   - Device offline scenarios
   - Database connection failures
   - WebSocket disconnections
   - Invalid data handling

### Step 6.3: Documentation & Deployment
**Time:** 4 hours

**Documentation Updates:**
- [ ] API documentation for trendlog endpoints
- [ ] User guide for trending configuration
- [ ] Installation and setup instructions
- [ ] Troubleshooting guide

**Deployment Checklist:**
- [ ] Database migration scripts
- [ ] Configuration file updates
- [ ] Service startup scripts
- [ ] Backup and recovery procedures

---

## 📊 Timeline Summary

| Phase | Duration | Key Deliverables |
|-------|----------|------------------|
| **Phase 1** | 2 days | Clean rollback, verified system state |
| **Phase 2** | 3 days | Trendlog database schema, dual connections |
| **Phase 3** | 5 days | Background collection service |
| **Phase 4** | 5 days | REST API + WebSocket implementation |
| **Phase 5** | 5 days | Frontend integration |
| **Phase 6** | 7 days | Testing, documentation, deployment |
| **Total** | **27 days** | **Complete trendlog system** |

---

## 🎯 Success Criteria

### Functional Requirements ✅
- [ ] Historical data storage for all device points
- [ ] Configurable collection intervals (1min - 4day)
- [ ] Real-time data streaming via WebSocket
- [ ] Interactive trend visualization in Vue.js
- [ ] Data export functionality (CSV/Excel)
- [ ] Multi-device, multi-point trending support

### Performance Requirements ✅
- [ ] Support 40 devices with 256 points each
- [ ] Handle years of historical data efficiently
- [ ] Real-time updates under 1 second latency
- [ ] Query response time under 5 seconds for normal ranges
- [ ] Minimal impact on existing T3000 performance

### Reliability Requirements ✅
- [ ] Data integrity during system failures
- [ ] Automatic recovery from device disconnections
- [ ] Graceful handling of database issues
- [ ] No impact on existing WebView functionality
- [ ] Backward compatibility with current features

---

## 🚀 Next Steps

**Ready to start?** The implementation plan is complete and ready for execution.

**Immediate Actions:**
1. **Execute Phase 1 rollback** (1 hour)
2. **Set up development environment** (30 minutes)
3. **Begin Phase 2 database implementation** (4 hours)

Would you like me to:
- ✅ **Start with Phase 1 rollback execution?**
- ✅ **Begin implementing any specific phase?**
- ✅ **Provide more detailed code examples for any section?**
- ✅ **Adjust timeline or requirements?**

---

**Document Version:** 1.0
**Last Updated:** August 7, 2025
**Author:**
**Status:** 🟡 Ready for Implementation
**Estimated Completion:** September 3, 2025
