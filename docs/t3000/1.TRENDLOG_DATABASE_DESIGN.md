# T3000 Trendlog Database Design - Comprehensive Analysis & Solution

**Date:** August 7, 2025
**Branch:** feature/new-ui
**Status:** Design Phase - No Implementation Yet

---

## Executive Summary

This document provides a comprehensive solution for implementing historical data storage in the T3000 WebView system. Currently, the system only provides real-time data through WebView2/WebSocket messages. This design introduces a separate SQLite database specifically for trendlog historical data while preserving existing functionality.

---

## Current System Analysis

### üèóÔ∏è Existing Architecture

```
T3000 C++ Application (Main Process)
‚îú‚îÄ‚îÄ Hardware Communication (BACnet/Modbus)
‚îÇ   ‚îú‚îÄ‚îÄ INPUT Sensors: 64 points per device
‚îÇ   ‚îú‚îÄ‚îÄ OUTPUT Actuators: 64 points per device
‚îÇ   ‚îî‚îÄ‚îÄ VARIABLE Points: 128 points per device
‚îú‚îÄ‚îÄ t3_webview_api.dll (Rust API Server)
‚îÇ   ‚îú‚îÄ‚îÄ WebSocket Server: Port 9104
‚îÇ   ‚îú‚îÄ‚îÄ HTTP API: Port 9103
‚îÇ   ‚îî‚îÄ‚îÄ Database: webview_database.db
‚îî‚îÄ‚îÄ Vue.js Frontend
    ‚îú‚îÄ‚îÄ Built-in WebView2 (embedded in T3000)
    ‚îú‚îÄ‚îÄ External Browser Support (http://localhost:9103)
    ‚îî‚îÄ‚îÄ Real-time Communication Only
```

### üìä Current Data Flow

```
Hardware Devices ‚Üí T3000 C++ ‚Üí Rust API ‚Üí Vue Frontend
     ‚Üë                ‚Üë           ‚Üë           ‚Üë
BACnet/Modbus    Message Loop   WebSocket    Live Display
   Protocol                    HTTP API     (No History)
```

### üìÅ Current Database Usage (webview_database.db)

**Purpose:** Modbus register management and configuration
- `modbus_register` - Modbus register definitions
- `modbus_register_devices` - Device registry
- `modbus_register_settings` - Configuration
- `user` - Authentication data

**Current Tables:**
```sql
modbus_register              -- Register definitions
modbus_register_devices      -- Device registry
modbus_register_settings     -- System settings
user                         -- User authentication
files                        -- File management
```

---

## üéØ Problem Statement

### Current Limitations
- ‚ùå **No Historical Data Storage** - Only real-time values available
- ‚ùå **No Trending Capability** - Cannot view data over time
- ‚ùå **No Data Analysis** - Missing historical patterns and insights
- ‚ùå **No Performance Monitoring** - Cannot track system performance trends
- ‚ùå **No Reporting** - Limited data export and reporting capabilities

### User Requirements
- ‚úÖ **Store historical sensor data** from INPUT, OUTPUT, VARIABLE points
- ‚úÖ **Configurable collection intervals** (1 minute to 4 days)
- ‚úÖ **Real-time trending charts** in Vue.js interface
- ‚úÖ **Data export functionality** (CSV, Excel formats)
- ‚úÖ **Multiple device support** (up to 40 devices)
- ‚úÖ **Background collection** without user interaction
- ‚úÖ **Performance optimization** for large datasets

---

## üóÑÔ∏è Proposed Solution: Comprehensive T3000 Database Architecture

### Design Philosophy
**Unified T3000 System:** Create a comprehensive database (t3_device.db) that supports the complete T3000 ecosystem including buildings, devices, points, schedules, programs, and trendlogs, while preserving existing webview functionality.

### Database Strategy
```
üìÅ api/Database/
‚îú‚îÄ‚îÄ webview_database.db     (EXISTING - Unchanged)
‚îÇ   ‚îú‚îÄ‚îÄ Modbus register management
‚îÇ   ‚îú‚îÄ‚îÄ User authentication
‚îÇ   ‚îú‚îÄ‚îÄ File management
‚îÇ   ‚îî‚îÄ‚îÄ WebView configuration
‚îÇ
‚îî‚îÄ‚îÄ t3_device.db           (NEW - Comprehensive T3000 System)
    ‚îú‚îÄ‚îÄ Building hierarchy (Buildings ‚Üí Floors ‚Üí Rooms)
    ‚îú‚îÄ‚îÄ Network and device management
    ‚îú‚îÄ‚îÄ Complete point system (Inputs, Outputs, Variables)
    ‚îú‚îÄ‚îÄ Scheduling system (Schedules, Holidays, Programs)
    ‚îú‚îÄ‚îÄ Historical trending and data collection
    ‚îú‚îÄ‚îÄ Alarms and event management
    ‚îî‚îÄ‚îÄ Advanced T3000 features
```

### Key Design Decisions
- **No Foreign Key Constraints**: Removed for better performance and flexibility
- **Application-Level Integrity**: Data relationships managed in Rust code
- **80+ Device Types**: Full support for all T3000 product models
- **Comprehensive Schema**: Based on actual T3000 C++ source code analysis

---

## üèóÔ∏è Comprehensive T3000 Database Schema (t3_device.db)

### Core Tables Design

#### 1. Building Infrastructure
```sql
-- Buildings and Infrastructure
CREATE TABLE buildings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    description TEXT,
    address TEXT,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE TABLE floors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    building_id INTEGER NOT NULL,
    floor_number INTEGER NOT NULL,
    name TEXT NOT NULL,
    description TEXT,
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE TABLE rooms (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    floor_id INTEGER NOT NULL,
    room_number TEXT NOT NULL,
    name TEXT NOT NULL,
    description TEXT,
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- Networks and Devices
CREATE TABLE networks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    building_id INTEGER NOT NULL,
    name TEXT NOT NULL,
    network_type TEXT NOT NULL, -- 'BACnet', 'Modbus', 'TCP/IP'
    network_number INTEGER,
    description TEXT,
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE TABLE devices (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    network_id INTEGER NOT NULL,
    room_id INTEGER,
    device_instance INTEGER NOT NULL,
    modbus_id INTEGER,
    product_type INTEGER NOT NULL,    -- PM_TSTAT5B=1, PM_TSTAT6=6, etc.
    product_name TEXT NOT NULL,
    device_name TEXT NOT NULL,
    ip_address TEXT,
    mac_address TEXT,
    serial_number TEXT,
    firmware_version TEXT,
    hardware_version TEXT,
    panel_number INTEGER,
    sub_panel_number INTEGER,
    status TEXT DEFAULT 'offline',    -- 'online', 'offline', 'error'
    last_seen INTEGER,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);
```

#### 2. Point System (Based on T3000 C++ Analysis)
```sql
-- Input Points (Sensors)
CREATE TABLE input_points (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    point_index INTEGER NOT NULL,
    point_name TEXT NOT NULL,
    full_label TEXT,
    description TEXT,
    auto_manual INTEGER DEFAULT 0,    -- 0=Auto, 1=Manual
    value REAL,
    units_id INTEGER,
    range_type INTEGER,
    range_min REAL,
    range_max REAL,
    calibration REAL DEFAULT 0,
    filter INTEGER DEFAULT 0,
    signal_type TEXT,                 -- 'Analog', 'Digital', 'Virtual'
    function_type INTEGER,
    custom_table_id INTEGER,
    object_type INTEGER DEFAULT 0,    -- BACnet object type
    object_instance INTEGER,
    status TEXT DEFAULT 'normal',
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- Output Points (Actuators)
CREATE TABLE output_points (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    point_index INTEGER NOT NULL,
    point_name TEXT NOT NULL,
    full_label TEXT,
    description TEXT,
    auto_manual INTEGER DEFAULT 0,
    hoa_switch INTEGER DEFAULT 0,     -- Hand/Off/Auto
    value REAL,
    units_id INTEGER,
    range_type INTEGER,
    range_min REAL,
    range_max REAL,
    low_voltage REAL,
    high_voltage REAL,
    pwm_period INTEGER,
    signal_type TEXT,
    function_type INTEGER,
    interlock_conditions TEXT,
    off_on_delay INTEGER DEFAULT 0,
    on_off_delay INTEGER DEFAULT 0,
    object_type INTEGER DEFAULT 1,    -- BACnet Analog/Binary Output
    object_instance INTEGER,
    status TEXT DEFAULT 'normal',
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- Variable Points
CREATE TABLE variable_points (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    point_index INTEGER NOT NULL,
    point_name TEXT NOT NULL,
    full_label TEXT,
    description TEXT,
    auto_manual INTEGER DEFAULT 0,
    value REAL,
    units_id INTEGER,
    range_type INTEGER,
    range_min REAL,
    range_max REAL,
    object_type INTEGER DEFAULT 2,    -- BACnet Analog Value
    object_instance INTEGER,
    status TEXT DEFAULT 'normal',
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);
```

#### 3. Scheduling and Control System
```sql
-- Schedules
CREATE TABLE schedules (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    schedule_index INTEGER NOT NULL,
    schedule_name TEXT NOT NULL,
    description TEXT,
    auto_manual INTEGER DEFAULT 0,
    output_point_id INTEGER,
    holiday1_id INTEGER,
    holiday1_status INTEGER,
    holiday2_id INTEGER,
    holiday2_status INTEGER,
    status TEXT DEFAULT 'inactive',
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE TABLE schedule_details (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    schedule_id INTEGER NOT NULL,
    day_of_week INTEGER NOT NULL,     -- 0=Sunday, 1=Monday, etc.
    time_slot INTEGER NOT NULL,       -- 1-8 time slots per day
    start_time TEXT,                  -- 'HH:MM' format
    end_time TEXT,                    -- 'HH:MM' format
    value REAL
);

-- Holidays (Annual Routines)
CREATE TABLE holidays (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    holiday_index INTEGER NOT NULL,
    holiday_name TEXT NOT NULL,
    description TEXT,
    auto_manual INTEGER DEFAULT 0,
    date_start TEXT,                  -- 'YYYY-MM-DD' format
    date_end TEXT,                    -- 'YYYY-MM-DD' format
    value REAL,
    status TEXT DEFAULT 'inactive',
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- Programs
CREATE TABLE programs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    program_index INTEGER NOT NULL,
    program_name TEXT NOT NULL,
    description TEXT,
    auto_manual INTEGER DEFAULT 0,
    program_size INTEGER DEFAULT 0,
    execution_time INTEGER DEFAULT 0,
    program_text TEXT,
    status TEXT DEFAULT 'stopped',    -- 'running', 'stopped', 'error'
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);
```

#### 4. Trending and Historical Data
```sql
-- Trendlogs
CREATE TABLE trendlogs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    trendlog_index INTEGER NOT NULL,
    trendlog_name TEXT NOT NULL,
    description TEXT,
    point_type TEXT NOT NULL,         -- 'Input', 'Output', 'Variable'
    point_id INTEGER NOT NULL,        -- References input_points, output_points, or variable_points
    interval_seconds INTEGER NOT NULL,
    buffer_size INTEGER DEFAULT 1000,
    status TEXT DEFAULT 'inactive',   -- 'active', 'inactive', 'full'
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE TABLE trendlog_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    trendlog_id INTEGER NOT NULL,
    timestamp INTEGER NOT NULL,
    value REAL NOT NULL,
    quality INTEGER DEFAULT 0,        -- 0=Good, 1=Bad, 2=Uncertain
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- Timebase Configuration
CREATE TABLE timebase_config (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    interval_seconds INTEGER NOT NULL,
    retention_days INTEGER NOT NULL,
    description TEXT,
    is_active INTEGER DEFAULT 1,
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);
```

#### 5. Supporting Tables
```sql
-- Engineering Units
CREATE TABLE units (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    unit_name TEXT UNIQUE NOT NULL,
    unit_symbol TEXT,
    unit_type TEXT,                   -- 'Temperature', 'Pressure', 'Flow', etc.
    conversion_factor REAL DEFAULT 1.0
);

-- Custom Tables (for sensor calibration)
CREATE TABLE custom_tables (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    table_name TEXT NOT NULL,
    table_data TEXT                   -- JSON serialized table data
);

-- Alarms and Events
CREATE TABLE alarms (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    alarm_index INTEGER NOT NULL,
    message TEXT NOT NULL,
    alarm_time INTEGER NOT NULL,
    acknowledged INTEGER DEFAULT 0,   -- 0=No, 1=Yes
    acknowledged_by TEXT,
    acknowledged_time INTEGER,
    resolved INTEGER DEFAULT 0,       -- 0=No, 1=Yes
    resolved_time INTEGER,
    priority INTEGER DEFAULT 0,       -- 0=Low, 1=Medium, 2=High, 3=Critical
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- PID Controllers
CREATE TABLE pid_controllers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id INTEGER NOT NULL,
    pid_index INTEGER NOT NULL,
    input_point_id INTEGER,
    output_point_id INTEGER,
    setpoint_point_id INTEGER,
    proportional_gain REAL DEFAULT 1.0,
    integral_time INTEGER DEFAULT 0,
    derivative_time INTEGER DEFAULT 0,
    bias REAL DEFAULT 0,
    action TEXT DEFAULT 'DIRECT',     -- 'DIRECT', 'REVERSE'
    auto_manual INTEGER DEFAULT 0,
    status TEXT DEFAULT 'inactive',
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);
```

#### 6. Performance Indexes (No Foreign Keys)
```sql
-- Device and Point Indexes
CREATE INDEX idx_devices_instance ON devices(device_instance);
CREATE INDEX idx_devices_product_type ON devices(product_type);
CREATE INDEX idx_devices_network ON devices(network_id);
CREATE INDEX idx_devices_status ON devices(status);

-- Point Indexes
CREATE INDEX idx_input_points_device ON input_points(device_id);
CREATE INDEX idx_input_points_index ON input_points(device_id, point_index);
CREATE INDEX idx_output_points_device ON output_points(device_id);
CREATE INDEX idx_output_points_index ON output_points(device_id, point_index);
CREATE INDEX idx_variable_points_device ON variable_points(device_id);
CREATE INDEX idx_variable_points_index ON variable_points(device_id, point_index);

-- Trending Indexes
CREATE INDEX idx_trendlogs_device ON trendlogs(device_id);
CREATE INDEX idx_trendlogs_point ON trendlogs(point_type, point_id);
CREATE INDEX idx_trendlog_data_time ON trendlog_data(trendlog_id, timestamp);
CREATE INDEX idx_trendlog_data_timestamp ON trendlog_data(timestamp);

-- Schedule Indexes
CREATE INDEX idx_schedules_device ON schedules(device_id);
CREATE INDEX idx_schedule_details_schedule ON schedule_details(schedule_id);
CREATE INDEX idx_holidays_device ON holidays(device_id);
CREATE INDEX idx_programs_device ON programs(device_id);

-- Alarm Indexes
CREATE INDEX idx_alarms_device_time ON alarms(device_id, alarm_time);
CREATE INDEX idx_alarms_priority ON alarms(priority);
CREATE INDEX idx_alarms_status ON alarms(acknowledged, resolved);
```

---

## üîÑ Data Collection Architecture

### Collection Service Design
```
Background Collection Service (Rust)
‚îú‚îÄ‚îÄ Device Scanner
‚îÇ   ‚îú‚îÄ‚îÄ Auto-discover T3000 devices on network
‚îÇ   ‚îú‚îÄ‚îÄ Register devices in trendlog database
‚îÇ   ‚îî‚îÄ‚îÄ Monitor device online/offline status
‚îú‚îÄ‚îÄ Point Manager
‚îÇ   ‚îú‚îÄ‚îÄ Auto-configure trending for active points
‚îÇ   ‚îú‚îÄ‚îÄ Apply timebase intervals based on point type
‚îÇ   ‚îî‚îÄ‚îÄ Enable/disable trending per user configuration
‚îú‚îÄ‚îÄ Data Collector
‚îÇ   ‚îú‚îÄ‚îÄ Schedule collection based on intervals
‚îÇ   ‚îú‚îÄ‚îÄ Read point values via T3000 C++ bridge
‚îÇ   ‚îú‚îÄ‚îÄ Validate and store data
‚îÇ   ‚îî‚îÄ‚îÄ Handle communication errors gracefully
‚îî‚îÄ‚îÄ Real-time Broadcaster
    ‚îú‚îÄ‚îÄ Send updates via WebSocket (port 9104)
    ‚îú‚îÄ‚îÄ Notify frontend of new data
    ‚îî‚îÄ‚îÄ Push device status changes
```

### Collection Flow Process
```
1. Service Startup
   ‚îú‚îÄ‚îÄ Connect to trendlog_database.db
   ‚îú‚îÄ‚îÄ Load enabled devices and points
   ‚îú‚îÄ‚îÄ Initialize collection schedules
   ‚îî‚îÄ‚îÄ Start background collection tasks

2. Device Discovery Loop (Every 5 minutes)
   ‚îú‚îÄ‚îÄ Scan T3000 network for devices
   ‚îú‚îÄ‚îÄ Compare with database device list
   ‚îú‚îÄ‚îÄ Add new devices automatically
   ‚îî‚îÄ‚îÄ Update device last_seen timestamps

3. Point Collection Loop (Per configured interval)
   ‚îú‚îÄ‚îÄ For each enabled point:
   ‚îÇ   ‚îú‚îÄ‚îÄ Read current value from T3000
   ‚îÇ   ‚îú‚îÄ‚îÄ Validate value against min/max bounds
   ‚îÇ   ‚îú‚îÄ‚îÄ Store in trend_data table
   ‚îÇ   ‚îî‚îÄ‚îÄ Broadcast to WebSocket clients
   ‚îú‚îÄ‚îÄ Update collection_status
   ‚îî‚îÄ‚îÄ Handle and log any errors

4. Maintenance Tasks (Daily)
   ‚îú‚îÄ‚îÄ Clean up old data based on retention policies
   ‚îú‚îÄ‚îÄ Optimize database (VACUUM, REINDEX)
   ‚îú‚îÄ‚îÄ Generate collection statistics
   ‚îî‚îÄ‚îÄ Archive old data if needed
```

---

## üì° API Design for Trendlog

### REST API Endpoints (Port 9103)

#### Device Management
```http
GET    /api/trendlog/devices                    # List all devices
POST   /api/trendlog/devices                    # Add device to trending
GET    /api/trendlog/devices/{device_id}        # Get device details
PUT    /api/trendlog/devices/{device_id}        # Update device settings
DELETE /api/trendlog/devices/{device_id}        # Remove device from trending
GET    /api/trendlog/devices/{device_id}/status # Get device collection status
```

#### Point Configuration
```http
GET    /api/trendlog/points                     # List all trend points
POST   /api/trendlog/points                     # Configure point for trending
GET    /api/trendlog/points/{point_id}          # Get point configuration
PUT    /api/trendlog/points/{point_id}          # Update point settings
DELETE /api/trendlog/points/{point_id}          # Disable point trending
GET    /api/trendlog/points/device/{device_id}  # Get points for device
```

#### Historical Data Queries
```http
GET    /api/trendlog/data/{point_id}            # Get historical data for point
POST   /api/trendlog/data/query                 # Advanced multi-point queries
GET    /api/trendlog/data/latest/{point_id}     # Get latest value for point
GET    /api/trendlog/data/export                # Export data (CSV/Excel)
```

#### Collection Control
```http
GET    /api/trendlog/collection/status          # Get collection service status
POST   /api/trendlog/collection/start           # Start collection for device/point
POST   /api/trendlog/collection/stop            # Stop collection for device/point
GET    /api/trendlog/collection/statistics      # Get collection statistics
```

#### Timebase Management
```http
GET    /api/trendlog/timebase                   # List available intervals
POST   /api/trendlog/timebase                   # Create custom interval
PUT    /api/trendlog/timebase/{id}              # Update interval settings
```

### WebSocket Messages (Port 9104)

#### Real-time Data Updates
```javascript
// Trend data update
{
  "type": "trend_update",
  "point_id": 123,
  "device_id": 45,
  "timestamp": 1691400000,
  "value": 23.5,
  "quality": 0
}

// Device status change
{
  "type": "device_status",
  "device_id": 45,
  "online": true,
  "last_seen": 1691400000
}

// Collection service status
{
  "type": "collection_status",
  "active_devices": 15,
  "active_points": 380,
  "collections_per_minute": 45.2,
  "errors": []
}
```

---

## üé® Frontend Integration

### Vue.js Component Updates

#### TrendLogChart.vue Enhancement
```vue
<template>
  <div class="trendlog-chart">
    <!-- Device and Point Selection -->
    <div class="selection-panel">
      <device-selector
        v-model="selectedDevices"
        :available-devices="availableDevices"
        @selection-change="onDeviceSelectionChange"
      />
      <point-selector
        v-model="selectedPoints"
        :devices="selectedDevices"
        @selection-change="onPointSelectionChange"
      />
    </div>

    <!-- Time Range Controls -->
    <div class="time-controls">
      <time-range-picker
        v-model="timeRange"
        :preset-ranges="presetRanges"
        @range-change="onTimeRangeChange"
      />
      <realtime-toggle
        v-model="realtimeEnabled"
        :update-interval="realtimeInterval"
        @toggle="onRealtimeToggle"
      />
    </div>

    <!-- Chart Display -->
    <div class="chart-container">
      <chart-js
        ref="trendChart"
        :data="chartData"
        :options="chartOptions"
        @zoom="onChartZoom"
        @pan="onChartPan"
      />
    </div>

    <!-- Export and Analysis Tools -->
    <div class="tools-panel">
      <export-controls
        :selected-points="selectedPoints"
        :time-range="timeRange"
        @export="onDataExport"
      />
      <analysis-tools
        :chart-data="chartData"
        @analyze="onDataAnalysis"
      />
    </div>
  </div>
</template>

<script>
import { useTrendlog } from '@/composables/useTrendlog';
import { useWebSocket } from '@/composables/useWebSocket';

export default {
  name: 'TrendLogChart',
  setup() {
    const {
      availableDevices,
      selectedDevices,
      selectedPoints,
      timeRange,
      chartData,
      loadDevices,
      loadHistoricalData,
      exportData
    } = useTrendlog();

    const {
      isConnected,
      connect,
      subscribe,
      unsubscribe
    } = useWebSocket();

    // Real-time data handling
    const handleRealtimeData = (message) => {
      if (message.type === 'trend_update') {
        updateChartData(message);
      }
    };

    return {
      availableDevices,
      selectedDevices,
      selectedPoints,
      timeRange,
      chartData,
      isConnected,
      loadDevices,
      loadHistoricalData,
      exportData,
      handleRealtimeData
    };
  }
};
</script>
```

#### Composables for Trendlog Integration

```javascript
// composables/useTrendlog.js
import { ref, reactive, computed } from 'vue';
import { TrendlogAPI } from '@/api/trendlog';

export function useTrendlog() {
  const availableDevices = ref([]);
  const selectedDevices = ref([]);
  const selectedPoints = ref([]);
  const timeRange = reactive({
    start: new Date(Date.now() - 24 * 60 * 60 * 1000), // 24 hours ago
    end: new Date()
  });
  const chartData = ref([]);

  const api = new TrendlogAPI();

  const loadDevices = async () => {
    try {
      availableDevices.value = await api.getDevices();
    } catch (error) {
      console.error('Failed to load devices:', error);
    }
  };

  const loadHistoricalData = async () => {
    if (selectedPoints.value.length === 0) return;

    try {
      const promises = selectedPoints.value.map(pointId =>
        api.getHistoricalData(pointId, timeRange.start, timeRange.end)
      );
      const results = await Promise.all(promises);
      chartData.value = processChartData(results);
    } catch (error) {
      console.error('Failed to load historical data:', error);
    }
  };

  const exportData = async (format = 'csv') => {
    try {
      const exportQuery = {
        point_ids: selectedPoints.value,
        start_time: timeRange.start.getTime() / 1000,
        end_time: timeRange.end.getTime() / 1000,
        format: format
      };
      const blob = await api.exportData(exportQuery);
      downloadFile(blob, `trendlog_export.${format}`);
    } catch (error) {
      console.error('Failed to export data:', error);
    }
  };

  return {
    availableDevices,
    selectedDevices,
    selectedPoints,
    timeRange,
    chartData,
    loadDevices,
    loadHistoricalData,
    exportData
  };
}
```

---

## ‚ö° Performance Optimization

### Database Optimization

#### Indexing Strategy
```sql
-- Primary performance indexes (already included above)
CREATE INDEX idx_trend_data_point_time ON trend_data(point_id, timestamp);
CREATE INDEX idx_trend_data_timestamp ON trend_data(timestamp);

-- Additional composite indexes for common queries
CREATE INDEX idx_trend_data_time_quality ON trend_data(timestamp, quality);
CREATE INDEX idx_trend_points_device_enabled ON trend_points(device_id, is_enabled);
CREATE INDEX idx_devices_active_type ON devices(is_active, device_type);
```

#### Data Retention and Archival
```sql
-- Automatic cleanup trigger for old data
CREATE TRIGGER cleanup_old_trend_data
AFTER INSERT ON trend_data
WHEN (SELECT COUNT(*) FROM trend_data) > 1000000  -- 1M records threshold
BEGIN
  DELETE FROM trend_data
  WHERE timestamp < (strftime('%s', 'now') -
    (SELECT MIN(retention_days * 86400) FROM timebase_config WHERE is_active = 1));
END;
```

#### Query Optimization
```rust
// Efficient batch queries for large datasets
pub async fn get_trend_data_optimized(
    conn: &DatabaseConnection,
    point_ids: Vec<u32>,
    start_time: i64,
    end_time: i64,
    max_points: Option<u32>
) -> Result<Vec<TrendDataPoint>, DbErr> {
    let max_points = max_points.unwrap_or(10000);

    // Calculate optimal sampling interval for large datasets
    let time_span = end_time - start_time;
    let estimated_points = point_ids.len() as u32 * (time_span / 60) as u32; // Assume 1-minute intervals

    let query = if estimated_points > max_points {
        // Use sampling for large datasets
        let sample_interval = estimated_points / max_points;
        trend_data::Entity::find()
            .filter(trend_data::Column::PointId.is_in(point_ids))
            .filter(trend_data::Column::Timestamp.between(start_time, end_time))
            .filter(Expr::expr(Func::cust(format!("id % {}", sample_interval)).eq(0)))
    } else {
        // Return all data for smaller datasets
        trend_data::Entity::find()
            .filter(trend_data::Column::PointId.is_in(point_ids))
            .filter(trend_data::Column::Timestamp.between(start_time, end_time))
    };

    query.all(conn).await
}
```

### Collection Performance

#### Batch Collection Strategy
```rust
// Collect multiple points per device in single operation
pub async fn collect_device_batch(device_id: u32) -> Result<Vec<PointData>, Error> {
    let points = get_enabled_points_for_device(device_id).await?;
    let mut results = Vec::new();

    // Group points by collection interval for efficiency
    let mut interval_groups: HashMap<u32, Vec<TrendPoint>> = HashMap::new();
    for point in points {
        interval_groups
            .entry(point.collection_interval)
            .or_insert_with(Vec::new)
            .push(point);
    }

    // Collect each interval group
    for (interval, group_points) in interval_groups {
        if should_collect_now(interval) {
            let batch_results = read_points_batch(device_id, group_points).await?;
            results.extend(batch_results);
        }
    }

    Ok(results)
}
```

#### Error Handling and Retry Logic
```rust
pub async fn collect_with_retry(
    device_id: u32,
    point: &TrendPoint,
    max_retries: u32
) -> Result<PointData, CollectionError> {
    let mut retries = 0;

    loop {
        match read_device_point(device_id, &point).await {
            Ok(data) => return Ok(data),
            Err(error) => {
                retries += 1;
                if retries >= max_retries {
                    // Log error and mark point as having issues
                    update_collection_status(
                        device_id,
                        Some(point.id),
                        CollectionStatus::Error(error.to_string())
                    ).await?;
                    return Err(error);
                }

                // Exponential backoff
                let delay = Duration::from_millis(100 * 2_u64.pow(retries - 1));
                tokio::time::sleep(delay).await;
            }
        }
    }
}
```

---

## üîí Security and Reliability

### Data Integrity
```sql
-- Constraints to ensure data integrity
ALTER TABLE trend_data ADD CONSTRAINT chk_timestamp
CHECK (timestamp > 0 AND timestamp <= strftime('%s', 'now'));

ALTER TABLE trend_data ADD CONSTRAINT chk_quality
CHECK (quality IN (0, 1, 2));  -- 0=good, 1=bad, 2=uncertain

-- Foreign key constraints (enabled with PRAGMA)
PRAGMA foreign_keys = ON;
```

### Backup and Recovery
```rust
pub async fn backup_trendlog_database() -> Result<(), Error> {
    let timestamp = chrono::Utc::now().format("%Y%m%d_%H%M%S");
    let backup_path = format!("Database/backups/trendlog_backup_{}.db", timestamp);

    // Use SQLite backup API for consistent backup
    let conn = get_trendlog_connection().await?;
    conn.execute(&format!("VACUUM INTO '{}'", backup_path), []).await?;

    // Keep only last 7 days of backups
    cleanup_old_backups("Database/backups/", 7).await?;

    Ok(())
}
```

### Access Control
```rust
// API endpoint security
pub async fn verify_trendlog_access(
    user: &User,
    action: TrendlogAction,
    resource: TrendlogResource
) -> Result<bool, AuthError> {
    match action {
        TrendlogAction::Read => {
            // All authenticated users can read trending data
            Ok(user.is_authenticated())
        },
        TrendlogAction::Configure => {
            // Only admin users can configure trending
            Ok(user.is_admin())
        },
        TrendlogAction::Export => {
            // Users with export permission can export data
            Ok(user.has_permission("trendlog_export"))
        }
    }
}
```

---

## üìà Testing Strategy

### Unit Tests
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_trendlog_database_operations() {
        let conn = setup_test_database().await;

        // Test device CRUD operations
        let device = create_test_device().await;
        assert!(device.id > 0);

        // Test point configuration
        let point = create_test_trend_point(device.device_id).await;
        assert!(point.is_enabled);

        // Test data storage and retrieval
        let data_points = generate_test_data(point.id, 100).await;
        store_trend_data_batch(&conn, data_points).await.unwrap();

        let retrieved = get_trend_data(&conn, point.id, 0, i64::MAX).await.unwrap();
        assert_eq!(retrieved.len(), 100);
    }

    #[tokio::test]
    async fn test_collection_service() {
        let service = CollectionService::new().await;

        // Test device discovery
        let devices = service.discover_devices().await.unwrap();
        assert!(!devices.is_empty());

        // Test data collection
        let collected = service.collect_device_data(devices[0].device_id).await.unwrap();
        assert!(!collected.is_empty());
    }

    #[tokio::test]
    async fn test_api_endpoints() {
        let app = create_test_app().await;

        // Test device listing
        let resp = app.get("/api/trendlog/devices").send().await;
        assert_eq!(resp.status(), StatusCode::OK);

        // Test historical data query
        let resp = app.get("/api/trendlog/data/1?start=0&end=9999999999").send().await;
        assert_eq!(resp.status(), StatusCode::OK);
    }
}
```

### Integration Tests
```rust
#[tokio::test]
async fn test_full_system_integration() {
    // Start the full system
    let _server = start_test_server().await;
    let collector = start_collection_service().await;

    // Simulate device data
    let device_id = 100;
    simulate_device_online(device_id).await;

    // Wait for automatic discovery and configuration
    tokio::time::sleep(Duration::from_secs(10)).await;

    // Verify device was discovered
    let devices = get_devices().await.unwrap();
    assert!(devices.iter().any(|d| d.device_id == device_id));

    // Verify data collection started
    tokio::time::sleep(Duration::from_secs(65)).await; // Wait for collection cycle

    let data = get_latest_data_for_device(device_id).await.unwrap();
    assert!(!data.is_empty());
}
```

---

## üöÄ Deployment and Migration

### Migration Strategy
```rust
// Migration: Add trendlog functionality without affecting existing system
pub async fn migrate_to_trendlog() -> Result<(), MigrationError> {
    // 1. Create trendlog database with schema
    create_trendlog_database().await?;

    // 2. Initialize timebase configuration
    initialize_default_timebase().await?;

    // 3. Discover and register existing devices
    discover_and_register_devices().await?;

    // 4. Start collection service
    start_collection_service().await?;

    // 5. Update API routes to include trendlog endpoints
    register_trendlog_routes().await?;

    Ok(())
}
```

### Configuration
```toml
# .env configuration for trendlog
TRENDLOG_DATABASE_PATH="Database/trendlog_database.db"
TRENDLOG_COLLECTION_ENABLED=true
TRENDLOG_DEFAULT_INTERVAL=60
TRENDLOG_MAX_RETENTION_DAYS=365
TRENDLOG_BACKUP_ENABLED=true
TRENDLOG_BACKUP_INTERVAL_HOURS=24
```

### Monitoring and Alerting
```rust
pub struct TrendlogMonitor {
    collection_rate: f64,
    error_rate: f64,
    database_size: u64,
    active_points: u32,
}

impl TrendlogMonitor {
    pub async fn check_health(&self) -> HealthStatus {
        let mut issues = Vec::new();

        if self.collection_rate < 0.9 {  // Less than 90% success rate
            issues.push("Low collection success rate".to_string());
        }

        if self.error_rate > 0.05 {  // More than 5% error rate
            issues.push("High error rate detected".to_string());
        }

        if self.database_size > 1_000_000_000 {  // > 1GB
            issues.push("Database size growing large".to_string());
        }

        if issues.is_empty() {
            HealthStatus::Healthy
        } else {
            HealthStatus::Warning(issues)
        }
    }
}
```

---

## üìã Implementation Checklist

### Phase 1: Database Foundation ‚úÖ
- [ ] Create trendlog_database.db schema
- [ ] Implement dual database connection management
- [ ] Create Sea-ORM entities for trendlog tables
- [ ] Set up database migrations
- [ ] Add indexes and constraints for performance

### Phase 2: Collection Service ‚úÖ
- [ ] Implement T3000 device discovery
- [ ] Create background collection service
- [ ] Add point configuration management
- [ ] Implement data validation and storage
- [ ] Add error handling and retry logic

### Phase 3: API Development ‚úÖ
- [ ] Create REST API endpoints for trendlog
- [ ] Implement WebSocket real-time updates
- [ ] Add data export functionality
- [ ] Implement query optimization
- [ ] Add authentication and authorization

### Phase 4: Frontend Integration ‚úÖ
- [ ] Update TrendLogChart.vue component
- [ ] Implement real-time data subscription
- [ ] Add historical data visualization
- [ ] Create device and point selection UI
- [ ] Add data export interface

### Phase 5: Testing and Deployment ‚úÖ
- [ ] Write comprehensive unit tests
- [ ] Implement integration tests
- [ ] Performance testing with large datasets
- [ ] Security testing and validation
- [ ] Documentation and user guides

---

## üéØ Success Metrics

### Functional Metrics
- **Data Collection Rate**: > 99% successful collections
- **Query Response Time**: < 5 seconds for typical queries
- **Real-time Latency**: < 1 second from collection to display
- **System Availability**: > 99.9% uptime
- **Data Accuracy**: 100% data integrity

### Performance Metrics
- **Concurrent Users**: Support 10+ simultaneous users
- **Device Capacity**: Handle 40 devices with 256 points each
- **Data Volume**: Efficiently manage years of historical data
- **Memory Usage**: < 500MB additional RAM usage
- **Disk Space**: Efficient storage with automatic cleanup

### User Experience Metrics
- **Setup Time**: < 5 minutes to configure first device
- **Learning Curve**: Intuitive interface requiring minimal training
- **Export Speed**: Export data in < 30 seconds for typical queries
- **Chart Responsiveness**: Smooth interaction with large datasets

---

## üìö Documentation Plan

### Technical Documentation
- [ ] **API Reference**: Complete REST API documentation with examples
- [ ] **Database Schema**: Detailed table descriptions and relationships
- [ ] **Collection Service**: Architecture and configuration guide
- [ ] **Performance Tuning**: Optimization guidelines and best practices

### User Documentation
- [ ] **Quick Start Guide**: Get trending working in 5 minutes
- [ ] **Configuration Manual**: Device and point setup procedures
- [ ] **Troubleshooting Guide**: Common issues and solutions
- [ ] **Advanced Features**: Power user capabilities and tips

### Developer Documentation
- [ ] **Integration Guide**: How to extend trendlog functionality
- [ ] **Custom Intervals**: Creating custom collection timebase
- [ ] **Plugin Architecture**: Adding custom data sources
- [ ] **Migration Guide**: Upgrading from previous versions

---

## üîÆ Future Enhancements

### Phase 2 Features (v2.0)
- **Data Analytics**: Statistical analysis and pattern detection
- **Alerting System**: Threshold-based notifications and alarms
- **Mobile App**: Dedicated mobile interface for trending
- **Cloud Sync**: Optional cloud backup and synchronization
- **Machine Learning**: Predictive analytics and anomaly detection

### Phase 3 Features (v3.0)
- **Multi-Site Support**: Centralized trending across multiple locations
- **Advanced Reporting**: Automated report generation and scheduling
- **Integration APIs**: Third-party system integration capabilities
- **Custom Dashboards**: User-configurable dashboard layouts
- **Data Federation**: Aggregate data from multiple T3000 systems

---

**Document Version:** 1.0
**Last Updated:** August 7, 2025
**Author:**
**Review Status:** ‚úÖ Ready for Implementation
